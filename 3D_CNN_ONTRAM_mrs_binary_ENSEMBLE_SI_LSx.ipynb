{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SI LSx: ONTRAM 3D CNN\n",
    "## Outcome: mRS binary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !python -m pip install -U scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from scipy import ndimage\n",
    "from sklearn import metrics\n",
    "from sklearn import linear_model\n",
    "\n",
    "# Tensorflow/Keras\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "from tensorflow import keras\n",
    "print(keras.__version__)\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Own functions\n",
    "from functions.plot_slices import plot_slices\n",
    "from functions.ontram import ontram\n",
    "from functions.fit_ontram import fit_ontram\n",
    "from functions.fit_ontram_batches import fit_ontram_batches\n",
    "from functions.plot_results import plot_results\n",
    "from functions.methods import predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# OUTPUT_VARIABLE = \"stroke\"\n",
    "OUTPUT_VARIABLE = \"mrs\"\n",
    "N_ENSEMBLES = 5\n",
    "N_FOLDS = 5\n",
    "MODEL_SELECTION = \"train\" # train, test or last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR = \"/tf/notebooks/katrin/\"\n",
    "OUTPUT_DIR = '{}results/mrs_binary/ensemble/'.format(DIR)\n",
    "INPUT_IMG = \"{}data/dicom_3d_128x128x30.h5\".format(DIR)\n",
    "INPUT_TAB = \"{}data/baseline_data_DWI_imputed.csv\".format(DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import tabular data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_TAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = pd.read_csv(INPUT_TAB, sep = ',')\n",
    "dat.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change values to numbers\n",
    "dat = dat.replace('no', 0)\n",
    "dat = dat.replace('yes', 1)\n",
    "dat.sex = dat.sex.replace('female', 1)\n",
    "dat.sex = dat.sex.replace('male', 0)\n",
    "dat.event = dat.event.replace('Stroke', 1)\n",
    "dat.event = dat.event.replace('TIA', 0)\n",
    "dat.p_id =[format(id, '03d') for id in dat.p_id]\n",
    "dat.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"number of missing outcomes: {}\".format(sum(dat.mrs_3months.isna())))\n",
    "missing_ids = dat.p_id[dat.mrs_3months.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove all patients with missing outcome\n",
    "keeps = [not i for i in dat.mrs_3months.isna()]\n",
    "dat = dat[keeps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(dat.mrs_3months.isna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables we have\n",
    "dat.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define mRS binary \n",
    "dat[\"mrs_3months_binary\"] = 1\n",
    "dat.loc[dat.mrs_3months <= 2, \"mrs_3months_binary\"] = 0\n",
    "plt.hist(dat.mrs_3months_binary, bins = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# match tabular data to image data\n",
    "# standardize age to 0 mean 1 variance\n",
    "X_tab = np.zeros((dat.shape[0], 12))\n",
    "Y_mrs = np.zeros((dat.shape[0]))\n",
    "Y_mrs_bin = np.zeros((dat.shape[0]))\n",
    "pat = []\n",
    "for i, p in enumerate(dat.p_id):\n",
    "    k = np.where(dat.p_id.values == p)[0][0]\n",
    "    dat_tmp = dat.iloc[k]\n",
    "    pat.append(dat_tmp.p_id)\n",
    "    X_tab[i,:] = np.array([dat_tmp.age, dat_tmp.sex, dat_tmp.mrs_before, dat_tmp.nihss_baseline, \n",
    "                           dat_tmp.stroke_before, dat_tmp.tia_before, dat_tmp.rf_hypertonia, \n",
    "                           dat_tmp.rf_diabetes, dat_tmp.rf_hypercholesterolemia, dat_tmp.rf_smoker, \n",
    "                           dat_tmp.rf_atrial_fibrillation, dat_tmp.rf_chd])\n",
    "    Y_mrs[i] = dat_tmp.mrs_3months\n",
    "    Y_mrs_bin[i] = dat_tmp.mrs_3months_binary\n",
    "X_tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if OUTPUT_VARIABLE == \"stroke\":\n",
    "    Y = Y_pat\n",
    "elif OUTPUT_VARIABLE == \"mrs\":\n",
    "    Y = Y_mrs_bin\n",
    "else:\n",
    "    raise ValueError(\"unknown OUTPUT_VARIABLE: {}\".format(OUTPUT_VARIABLE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define train validation test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get mrs = 0 and mrs = 1 indeces\n",
    "idx_0 = np.where(Y == 0)\n",
    "idx_1 = np.where(Y == 1)\n",
    "print(\"{} mRS 0 patients\".format(len(idx_0[0])))\n",
    "print(\"{} mRS 1 patients\".format(len(idx_1[0])))\n",
    "\n",
    "## shuffle indices\n",
    "np.random.seed(2021)\n",
    "np.random.shuffle(idx_0[0])\n",
    "np.random.shuffle(idx_1[0])\n",
    "\n",
    "## split indices into 5 parts\n",
    "splits_0 = np.array_split(idx_0[0], N_FOLDS)\n",
    "splits_1 = np.array_split(idx_1[0], N_FOLDS)\n",
    "\n",
    "## define chosen splits for each fold\n",
    "test_folds = [0, 1, 2, 3, 4]\n",
    "valid_folds = [1, 2, 3, 4, 0]\n",
    "train_folds = [[0, 1], [1, 2], [2, 3], [3, 4], [0, 4]] ## remove these splits for training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define models for tabular data\n",
    "### Simple intercept, linear shift (logistic regression)\n",
    "Train with\n",
    "- tabular data\n",
    "- outcome = mRS binary\n",
    "- Ensemble with 5 Models\n",
    "- 5-Fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple intercept\n",
    "def simple_intercept(y_dim, run):\n",
    "    initializer = keras.initializers.HeNormal(seed = 2802 + run)\n",
    "    in_ = keras.Input(shape = (1, ), name = \"bl_in\")\n",
    "    out_ = layers.Dense(y_dim - 1, activation = \"linear\",\n",
    "                        use_bias = False, name = \"bl_out\", \n",
    "                        kernel_initializer = initializer)(in_)\n",
    "    nn_bl = keras.Model(inputs = in_, outputs = out_)\n",
    "    return nn_bl\n",
    "\n",
    "# linear shift\n",
    "def linear_shift_x(x, run):\n",
    "    initializer = keras.initializers.HeNormal(seed = 2802 + run)\n",
    "    in_ = keras.Input(shape = x.shape[1:], name = 'x_in')\n",
    "    out_ = layers.Dense(1, activation = 'linear',\n",
    "                        use_bias = False, name = 'x_out', \n",
    "                        kernel_initializer = initializer)(in_)\n",
    "    nn_x = keras.Model(inputs = in_, outputs = out_)\n",
    "    return nn_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Models\n",
    "#### First run:\n",
    "- batch size = 128\n",
    "- small learning rate\n",
    "\n",
    "#### Second run:\n",
    "- batch size = n\n",
    "- large learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for fold in range(N_FOLDS):\n",
    "    \n",
    "    ## define train, test and validation splits\n",
    "    test_idx = np.concatenate((splits_0[test_folds[fold]], splits_1[test_folds[fold]]), axis = None)\n",
    "    valid_idx = np.concatenate((splits_0[valid_folds[fold]], splits_1[valid_folds[fold]]), axis = None)\n",
    "\n",
    "    train_0 = np.delete(splits_0, train_folds[fold], 0)\n",
    "    train_0 = [item for sublist in train_0 for item in sublist]\n",
    "    \n",
    "    train_1 = np.delete(splits_1, train_folds[fold], 0)\n",
    "    train_1 = [item for sublist in train_1 for item in sublist]\n",
    "    \n",
    "    train_idx = np.concatenate((train_0, train_1), axis = None)\n",
    "    \n",
    "    X_tab_train = X_tab[train_idx]\n",
    "    X_tab_test = X_tab[test_idx]\n",
    "    X_tab_valid = X_tab[valid_idx]\n",
    "    \n",
    "    Y_train = Y[train_idx]\n",
    "    Y_test = Y[test_idx]\n",
    "    Y_valid = Y[valid_idx] \n",
    "    \n",
    "    Y_train = to_categorical(Y_train)\n",
    "    Y_valid = to_categorical(Y_valid)\n",
    "    Y_test = to_categorical(Y_test)\n",
    "    \n",
    "    for run in range(N_ENSEMBLES):\n",
    "    \n",
    "        ## create output directory\n",
    "        folder_name = \"SI_LSx/fold_{}/run_{}/\".format(fold, run)\n",
    "        if not os.path.exists(OUTPUT_DIR + folder_name):\n",
    "            os.makedirs(OUTPUT_DIR + folder_name)\n",
    "       \n",
    "        print(\"training fold {}/{}, run {}/{}\".format(fold+1, N_FOLDS, run+1, N_ENSEMBLES))\n",
    "    \n",
    "        # define model\n",
    "        nn_bl = simple_intercept(Y_train.shape[1], run)\n",
    "        nn_x = linear_shift_x(X_tab_train, run)\n",
    "        \n",
    "        si_ls = ontram(nn_bl = nn_bl, nn_x = nn_x, response_varying = False)\n",
    "        \n",
    "        MODEL_SELECTION = \"train\"\n",
    "        hist = fit_ontram(si_ls, \n",
    "                          x_train = X_tab_train, y_train = Y_train,\n",
    "                          x_test = X_tab_valid, y_test = Y_valid,\n",
    "                          batch_size = 128,\n",
    "                          epochs = 200,\n",
    "                          optimizer = tf.keras.optimizers.Adam(lr = 0.01),\n",
    "                          balance_batches = False,\n",
    "                          output_dir = OUTPUT_DIR + folder_name,\n",
    "                          model_selection = MODEL_SELECTION)\n",
    "        \n",
    "        ## save training loss and accuracy\n",
    "        out = pd.DataFrame({'fold': fold,\n",
    "                            'run': run,\n",
    "                            'train_loss': hist[\"train_loss\"], \n",
    "                            'train_acc': hist[\"train_acc\"],\n",
    "                            'test_loss': hist[\"test_loss\"], \n",
    "                            'test_acc': hist[\"test_acc\"]})\n",
    "\n",
    "        ## save best model\n",
    "        if(MODEL_SELECTION == \"test\"): # test loss...\n",
    "            best_model = np.where(out.test_loss == np.min(out.test_loss))[0][0]\n",
    "        if(MODEL_SELECTION == \"train\"): # train loss...\n",
    "            best_model = np.where(out.train_loss == np.min(out.train_loss))[0][0]\n",
    "        if(MODEL_SELECTION == \"last\"): # last model\n",
    "            best_model = out.shape[0] - 1\n",
    "        print('model selection: {}'.format(MODEL_SELECTION))\n",
    "        print('best model run {}: {}'.format(run, best_model))\n",
    "        si_ls.model.load_weights('{}{}model-{:03d}.hdf5'.format(OUTPUT_DIR, folder_name, best_model))\n",
    "        \n",
    "        MODEL_SELECTION = \"last\"\n",
    "        hist = fit_ontram(si_ls, \n",
    "                          x_train = X_tab_train, y_train = Y_train,\n",
    "                          x_test = X_tab_valid, y_test = Y_valid,\n",
    "                          batch_size = X_tab_train.shape[0],\n",
    "                          epochs = 1000,\n",
    "                          optimizer = tf.keras.optimizers.Adam(lr = 0.1),\n",
    "                          balance_batches = False,\n",
    "                          output_dir = OUTPUT_DIR + folder_name,\n",
    "                          model_selection = MODEL_SELECTION)\n",
    "        \n",
    "        ## save training loss and accuracy\n",
    "        out = pd.DataFrame({'fold': fold,\n",
    "                            'run': run,\n",
    "                            'train_loss': hist[\"train_loss\"], \n",
    "                            'train_acc': hist[\"train_acc\"],\n",
    "                            'test_loss': hist[\"test_loss\"], \n",
    "                            'test_acc': hist[\"test_acc\"]})\n",
    "        \n",
    "        if run == 0 and fold == 0:\n",
    "            out.to_csv(\"{}SI_LSx/ensemble_history.csv\".format(OUTPUT_DIR), index = False)\n",
    "        else:\n",
    "            out.to_csv(\"{}SI_LSx/ensemble_history.csv\".format(OUTPUT_DIR), \n",
    "                       mode='a', header=False, index = False)\n",
    "            \n",
    "        ## save best model\n",
    "        if(MODEL_SELECTION == \"test\"): # test loss...\n",
    "            best_model = np.where(out.test_loss == np.min(out.test_loss))[0][0]\n",
    "        if(MODEL_SELECTION == \"train\"): # train loss...\n",
    "            best_model = np.where(out.train_loss == np.min(out.train_loss))[0][0]\n",
    "        if(MODEL_SELECTION == \"last\"): # last model\n",
    "            best_model = out.shape[0] - 1\n",
    "        print('model selection: {}'.format(MODEL_SELECTION))\n",
    "        print('best model run {}: {}'.format(run, best_model))\n",
    "        si_ls.model.load_weights('{}{}model-{:03d}.hdf5'.format(OUTPUT_DIR, folder_name, best_model))\n",
    "        si_ls.model.save_weights('{}SI_LSx/fold_{}/best_model_run{}.hdf5'.format(OUTPUT_DIR, fold, run))\n",
    "        \n",
    "        # predict model\n",
    "        pred = predict(si_ls, x = X_tab_test, y = Y_test)\n",
    "        out = pd.DataFrame({'pid': np.array(pat)[test_idx],\n",
    "                            'fold': fold,\n",
    "                            'run': run,\n",
    "                            'pred_prob_mrs0': pred[\"pdf\"][:, 0],\n",
    "                            'pred_prob_mrs1': pred[\"pdf\"][:, 1],\n",
    "                            'pred_label_mrs1': pred[\"response\"],\n",
    "                            'patient_label_mrs0': Y_test[:, 0],\n",
    "                            'patient_label_mrs1': Y_test[:, 1]})\n",
    "        if run == 0 and fold == 0:\n",
    "            out.to_csv(\"{}SI_LSx/ensemble_predictions.csv\".format(OUTPUT_DIR), index = False)\n",
    "        else:\n",
    "            out.to_csv(\"{}SI_LSx/ensemble_predictions.csv\".format(OUTPUT_DIR), \n",
    "                       mode='a', header=False, index = False)\n",
    "            \n",
    "        ## save model weights\n",
    "        names = ['intercept', 'age', 'sex', 'mrs_before', 'nihss_baseline', 'stroke_before', \n",
    "                     'tia_before', 'rf_hypertonia', 'rf_diabetes', 'rf_hypercholesterolemia', \n",
    "                     'rf_smoker', 'rf_atrial_fibrillation', 'rf_chd']\n",
    "        weights = np.concatenate((pred['theta'][0], np.array(pred['beta_w']).flatten()))\n",
    "        out = pd.DataFrame({'fold': fold,\n",
    "                            'run': run,\n",
    "                            'names': names,\n",
    "                            'coef': weights})\n",
    "        if run == 0 and fold == 0:\n",
    "            out.to_csv(\"{}SI_LSx/ensemble_weights.csv\".format(OUTPUT_DIR), index = False)\n",
    "        else:\n",
    "            out.to_csv(\"{}SI_LSx/ensemble_weights.csv\".format(OUTPUT_DIR), \n",
    "                       mode='a', header=False, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pd.read_csv(\"{}SI_LSx/ensemble_predictions.csv\".format(OUTPUT_DIR))\n",
    "pred.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = pd.read_csv(\"{}SI_LSx/ensemble_weights.csv\".format(OUTPUT_DIR))\n",
    "weights.head(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = pd.read_csv(\"{}SI_LSx/ensemble_history.csv\".format(OUTPUT_DIR))\n",
    "hist.head(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "nteract": {
   "version": "0.22.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
